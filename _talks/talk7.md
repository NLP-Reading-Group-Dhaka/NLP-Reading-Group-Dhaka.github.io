---
name: Neural Machine Translation and Sequence-to-sequence Models A Tutorial, Graham Neubig 2017
speakers:
  - Rabiul Awal
date: 2021-09-26
categories:
  - Seq2seq and Attention
  - Talk
links:
  - name: Recodring
    icon: video
    absolute_url: https://drive.google.com/file/d/1ZmiFOg_fqVzIsD5d4iV64iIUP4t-7JlV/view?usp=sharing
  - name: Pdf
    absolute_url: https://arxiv.org/pdf/1703.01619.pdf
---

This tutorial introduces a new and powerful set of techniques variously called "neural machine translation" or "neural sequence-to-sequence models". These techniques have been used in a number of tasks regarding the handling of human language, and can be a powerful tool in the toolbox of anyone who wants to model sequential data of some sort. The tutorial assumes that the reader knows the basics of math and programming, but does not assume any particular experience with neural networks or natural language processing. It attempts to explain the intuition behind the various methods covered, then delves into them with enough mathematical detail to understand them concretely, and culiminates with a suggestion for an implementation exercise, where readers can test that they understood the content in practice.
